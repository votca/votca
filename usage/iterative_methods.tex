\chapter{Iterative methods}
\label{sec:iterative_methods}

The following sections deal with the methods of Iterative Boltzmann Inversion
(\ibi), Inverse Monte Carlo (\imc), and Relative Entropy (\re).

In general, \ibi, \imc, and \re are implemented within the same
framework. Therefore, most settings and parameters of those methods are similar
and thus described in a general section (see
sec. \ref{sec:iterative_methods_imc}). Further information on iterative methods
follows in the next chapters, in particular on the \ibi, \imc, and \re methods.

\begin{figure}[h]
   \centering
   \includegraphics[width=7cm]{usage/fig/flow_ibi.eps}
   \caption{\label{fig:flow_ibi}Flowchart to perform iterative Boltzmann inversion.}
\end{figure}

\section{Iterative workflow control}
\label{sec:iterative_workflow}

\begin{figure}[t]
   \centering
   \includegraphics[width=7cm]{functionality/fig/flowchart.eps}
   \caption{\label{fig:flowchart}Block-scheme of the workflow control for the iterative methods. The most time-consuming parts are marked in red.}
\end{figure}

Iterative workflow control is essential for the \ibi, \imc, and \re methods.

The general idea of iterative workflow is sketched in fig.~\ref{fig:flowchart}. During the global initialization the initial guess for the coarse-grained potential is calculated from the reference function or converted from a given potential guess into the internal format. The actual iterative step starts with an iteration initialization. It searches for possible checkpoints and copies and converts files from the previous step and the base directory. Then, the simulation run is prepared by converting potentials into the format required by the external sampling program and the actual sampling is performed.

After sampling the phasespace, the potential update is calculated. Often, the update requires postprocessing, such as smoothing, interpolation, extrapolation or fitting to an analytical form.

Finally, the new potential is determined and postprocessed. If the iterative process continues, the next iterative step will start to initialize.

\subsubsection*{How to start:}

The first thing to do is generate reference distribution functions. These might come from experiments or from atomistic simulations. To get reasonable results out of the iterative process, the reference distributions should be of good quality (little noise, etc).

\votca can create initial guesses for the coarse-grained
potentials by boltzmann inverting the distribution function. If a custom initial
guess for an interaction shall be used instead, the table can be provided in
\textit{$<$interaction$>$.pot.in}. As already mentioned, \votca automatically creates potential tables to run a simulation. However, it does not know how to run a coarse-grained simulation. Therefore, all files needed to run a coarse-grained simulation, except for the potentials that are iteratively refined, must be provided and added to the \hyperlink{\cgref{inverse.filelist}}{filelist} in the settings \xml-file. If an atomistic topology and a mapping definition are present, \votca offers tools to assist the setup of a  coarse-grained topology (see chapter \ref{sec:usage:cgrun}).

To get an overview of how input files look like, it is suggested to take a look at one of the tutorials provided on \votcaweb.

In what follows we describe how to set up the iterative coarse-graining, run the main script, continue the run, and add customized scripts.

\subsection{Preparing the run}
\label{sec:preparing_the_run}
To start the first iteration, one has to prepare the input for the sampling program. This means that all files for running a coarse-grained simulation must be present and described in a separate \xml file, in our case \texttt{settings.xml} (see sec. \ref{sec:setting_files} for details). An extract from this file is given below. The only exception are tabulated potentials, which will be created and updated by the script in the course of the iterative process.

The input files include: target distributions, initial guess (optional) and a list of interactions to be iteratively refined. As a target distribution, any table file can be given (e.g. \gromacs output from \texttt{g\_rdf}). The program automatically takes care to resample the table to the correct grid spacing according to the options provided in \texttt{settings.xml}.

The initial guess is normally taken as a potential of mean force and is generated by Boltzmann-inversion of the corresponding distribution function. It is written in \texttt{step\_000/<name>.pot.new}. If you want to manually specify the initial guess for a specific interaction, write the potential table to a file called \texttt{<name>.pot.in} in the folder where you plan to run the iterative procedure.

A list of interactions to be iteratively refined has to be given in the options file. As an example, the \texttt{setting.xml} file for a propane is shown in listing~\ref{list:settings}. For more details,  see the full description of all options in ref.~\ref{sec:ref_options}.
\begin{figure}
\centering
\framebox[\textwidth]{\lstinputlisting{functionality/settings.xml}
}
\caption{\texttt{settings.xml} file specifies interactions to be refined, grid spacings, sampling engine, and the iterative method. The complete file can be found in the \texttt{propane/ibm} tutorial. 
\label{list:settings}
}
\end{figure}

\subsection{Starting the iterative process}
\label{sec:starting_iterative_process}
After all input files have been set up, the run can be started by
\begin{verbatim}
  csg_inverse --options settings.xml
\end{verbatim}

Each iteration is stored in a separate directory, named \texttt{step\_<iteration>}. \texttt{step\_000} is a special folder which contains the initial setup. For each new iteration, the files required to run the CG simulation (as specified in the config file) are copied to the current working directory. The updated potentials  are copied from the last step, \texttt{step\_<n-1>/<interaction>.pot.new}, and used as the new working potentials \texttt{step\_<n>/<interaction>.pot.cur}.

After the run preparation, all potentials are converted into the format of the sampling program and the simulation starts. Once the sampling has finished, analysis programs generate new distributions, which are stored in \texttt{<interaction>.dist.new}, and new potential updates, stored in \texttt{<interaction>.dpot.new}. 

Before adding the update to the old potential, it can be processed in the \texttt{post\_update} step. For each script that is specified in the postupdate, \texttt{<interaction>.dpot.new} is renamed  to \texttt{<interaction>.dpot.old} and stored in \texttt{<interaction>.dpot.<a-number>} before the processing script is called. Each processing script  uses the current potential update \texttt{<interaction>.dpot.cur} and writes the processed update to \texttt{<interaction>.dpot.new}. As an example, a pressure correction is implemented as a postupdate script within this framework.

After all postupdate scripts have been called, the update is added to the potential and the new potential \texttt{<interaction>.pot.new} is written. Additional post-processing of the potential can be performed in the \texttt{post\_add} step which is analogous to the \texttt{post\_update} step except for a potential instead of an update.

To summarize, we list all standard output files for each iterative step:

\begin{tabular}{ll}
\texttt{*.dist.new} & distribution functions of the current step \\
\texttt{*.dpot.new} & the final potential update, created by \texttt{calc\_update} \\
\texttt{*.dpot.<number>} & for each postupdate script, the \texttt{.dpot.new} is saved and a new one\\
&is created\\
\texttt{*.pot.cur} & the current potential used for the actual run\\
\texttt{*.pot.new} & the new potential after the add step \\
\texttt{*.pot.<number>} & same as \texttt{dpot.<number>} but for \texttt{post\_add}
\end{tabular}

If a sub-step fails during the iteration, additional information can be found in the log file. The name of the log file is specified in the steering \xml file.

\subsection{Restarting and continuing}
The interrupted or finished iterative process can be restarted either by extending a finished run or by restarting the interrupted run. When the script \prog{csg_inverse} is called, it automatically checks for a file called \texttt{done} in the current directory. If this file is found, the program assumes that the run is finished. To extend the run, simply increase \cgopt{inverse.iterations_max} in the settings file and remove the file called \texttt{done}. After that, \prog{csg_inverse} can be restarted, which will automatically recognize existing steps and continue after the last one.

If the iteration was interrupted, the script \prog{csg_inverse} might not be able to restart on its own. In this case, the easiest solution is to delete the last step and start again. The script will then repeat the last step and continue. However, this method is not always practical since sampling and analysis might be time-consuming and the run might have only crashed due to some inadequate post processing option. To avoid repeating the entire run, the script \prog{csg_inverse} creates a file with restart points and labels already completed steps such as simulation, analysis, etc. The file name is specified in the option \cgopt{inverse.restart_file}. If specific actions should be redone, one can simply remove the corresponding lines from this file. Note that a file \texttt{done} is also created in each folder for those steps which have been successfully finished.


% #####################################################################################################################
% #####################################################################################################################

\section{Iterative Boltzmann Inversion}
\subsection{Input preparation}
This section describes the usage of \ibi, implemented within the scripting framework described in the previous section \ref{sec:iterative_workflow}. It is suggested to get a basic understanding of this framework before proceeding.

An outline of the workflow for performing \ibi is given in \fig{fig:flow_ibi}.

To specify Iterative Boltzmann Inversion as algorithm in the script, add \texttt{ibi} in the \texttt{method} section of the \xml setting file as shown below.

\begin{lstlisting}
  <cg>
    ...
    <inverse>
      <method>ibi</method>
    </inverse>
  </cg>
\end{lstlisting}


% #####################################################################################################################
% #####################################################################################################################

\section{Inverse Monte Carlo}
\label{sec:iterative_methods_imc}
In this section, additional options are described to run \imc coarse graining. The usage of \imc is similar to the one of \ibi and understanding the use of the scripting framework described in chapter~\ref{sec:iterative_workflow} is necessary.

\textbf{WARNING: multicomponent \imc is still experimental!}

\subsection{General considerations}
In comparison to \ibi, \imc needs significantly more statistics to calculate the potential update\cite{Ruehle:2009.a}. It is advisable to perform smoothing on the potential update. Smoothing can be performed as described in \sect{ref:ibi:optimize}. In addition, \imc can lead to problems related to finite size: for methanol, an undersized system proved to lead to a linear shift in the potential\cite{Ruehle:2009.a}. It is therefore always necessary to check that the system size is sufficiently large and that runlength csg smoothing iterations are well balanced.

\subsection{Correlation groups}
Unlike \ibi, \imc also takes cross-correlations of interactions into account in order to calculate the update. However, it might not always be beneficial to evaluate cross-correlations of all pairs of interactions. By specifying \interopt{inverse.imc.group}, \votca allows to define groups of interactions, amongst which cross-correlations are taken into account, where \interopt{inverse.imc.group} can be any name.

\begin{lstlisting}
  <non-bonded>
    <name>CG-CG</name>
    <type1>CG</type1>
    <type2>CG</type2>
    ...
    <imc>
      <group>solvent</group>
   </imc>
  </non-bonded>
  <non-bonded>
\end{lstlisting}

\subsection{Regularization}

To use the regularized version of IMC a $\lambda$ value $>0$ has to be specified by setting \interopt{inverse.imc.reg}. 
If set to $0$ (default value) the unregularized version of IMC is applied.
\begin{lstlisting}
 <non-bonded>
   <name>CG-CG</name>
   <type1>CG</type1>
   <type2>CG</type2>
    ...
   <inverse>
     <imc>
       <reg>300</reg>
     </imc>
   </inverse>
 </non-bonded>
\end{lstlisting}
% #####################################################################################################################
% #####################################################################################################################

\section{Relative Entropy}
\label{sec:iterative_methods_re}
In this section, additional options are described to run \re coarse
graining. The usage of \re is similar to the one of \ibi and \imc and
understanding the use of the scripting framework described in
chapter~\ref{sec:iterative_workflow} is necessary.

Currently, \re implementation supports optimization of two-body
non-bonded pair interactions. Support for bonded and N-body interactions is
possible by further extension of \re implementation.

\subsection{Potential function and parameters}
In \re, CG potentials are modeled using analytical functional forms. Therefore,
for each CG interaction, an analytical functional must be specified in the \xml
setting file as
\begin{lstlisting}
  <non-bonded>
    <name>CG-CG</name>
    <type1>CG</type1>
    <type2>CG</type2>
    ...
    <re>
      <function>cbspl or lj126</function>
        <cbspl>
          <nknots>48</nknots>
        </cbspl>
    </re>
    ...
  </non-bonded>
\end{lstlisting}
Currently, standard Lennard-Jones 12-6 (lj126) and uniform cubic B-splines-based
piecewise polynomial (cbspl) functional forms are supported. For lj126, the
parameters to optimize are the usual $C_{12}$ and $C_{6}$. The cbspl form is
defined as
\begin{equation}
\label{eq:cbspl}
u_{\text{cbspl}}(r) = \left[\begin{array}{cccc}
    1 & t & t^2 & t^3 \end{array}\right]
\frac{1}{6}
\left[ \begin{array}{rrrr}
    1 & 4 & 1 & 0 \\
    -3 & 0 & 3 & 0 \\
    3 & -6 & 3 & 0 \\
    -1 & 3 & -3 & 1 \end{array}\right]
\left[ \begin{array}{l}
    c_{k} \\
    c_{k+1} \\
    c_{k+2} \\
    c_{k+3} \end{array}\right] ,
\end{equation}
where $\{c_0,c_1,c_2,...,c_m\}$ are the spline knot values tabulated for $m$
evenly spaced intervals of size $\Delta r = r_{\text{cut}}/(m-2)$ along the
separation distance $r_{i} = i\times\Delta r$ with the cut-off $r_{\text{cut}}$,
and $t$ is given by
\begin{equation}
\label{eq:cbspl_t}
t = \frac{r-r_{k}}{\Delta r} ,
\end{equation}
where index $k$ is determined such that $r_{k}\leq r < r_{k+1}$. For cbspl, the
knot values, $\{c_0,c_1,c_2,...,c_m\}$, are optimized. The number of knot values
to use must be specified in the \xml setting file as shown in the above
snippet. $u_{\text{cbspl}}(r)$ exhibits remarkable flexibility, and it can
represent various complex functional characteristics of pair potentials for
sufficiently large number of knots.

\subsection{Update scaling parameter}
Depending on the quality of the initial guess and sensitivity of the CG system
to the CG parameters, scaling of the parameter update size may be required to
ensure the stability and convergence of the \re minimization. The scaling
parameter, $\chi\in(0...1)$, value can be specified in the \xml settings file.

\subsection{Statistical averaging of parameters}
Due to stochastic nature of the CG simulations, near convergence, the CG
potential paramters may fluctuate around the mean converged values. Therefore,
the optimal CG parameters can be estimated by averaging over the last few
iterations. To specify averaging, the \texttt{average}, keyword should be
specified in the \texttt{post\_update} options in the \xml settings file.

\subsection{General considerations}
To ensure the stability of the relative entropy minimization, some precautionary
measures are taken. For the Newton-Raphson update to converge towards a minimum,
the Hessian, $\mathbf{H}$, must be positive definite at each step. With a good
initial guess for the CG parameters and by adjusting the value of the relaxation
parameter, $\chi$, stability of the Newton-Raphson method can be ensured. One
approach to initialize the CG parameters can be to fit them to PMF obtained by
inverting the pair distributions of the CG sites obtained from the reference AA
ensemble. For the lj126 and cbspl forms, which are linear in its parameters, the
second derivative of $S_{\text{rel}}$ is never negative, hence the minimization
converges to a single global minimum. However, due to locality property of the
cbspl form, i.e., update to $c_i$ affects only the value of the potential near
$r_i$, and the poor sampling of the very small separation distances in the high
repulsive core, the rows of $\mathbf{H}$ corresponding to the first few spline
knots in the repulsive core may become zero causing $\mathbf{H}$ to be a
singular matrix. To avoid this singularity issue, we specify a minimum
separation distance, $r_{\text{min}}$, for each CG pair interaction and remove
the spline knots corresponding to the $r\le r_{\text{min}}$ region from the
Newton-Raphson update. Once the remaining knot values are updated, the knot
values in the poorly sampled region, i.e., $r\le r_{\text{min}}$, are linearly
extrapolated. The value of $r_{\text{min}}$ at each iteration is estimated from
the minimum distance at which the CG RDF from the CG-MD simulation is
nonzero. Also, to ensure that the CG pair potentials and forces go smoothly to
zero near $r_{\text{cut}}$, 2 knot values before and after $r_{\text{cut}}$,
i.e., total 4, are fixed to zero.

% #####################################################################################################################
% #####################################################################################################################

\section{Pressure correction}

The pressure of the coarse-grained system usually does not match the pressure of the full atomistic system. This is because iterative Boltzmann inversion only targets structural properties but not thermodynamic properties. In order correct the pressure in such a way that it matches the target pressure (\interopt{inverse.p_target})., different strategies have been used based on small modifications of the potential. The correction can be enable by adding pressure to the list of \interopt{inverse.post_update} scripts. The type of pressure correction is selected by setting \interopt{inverse.post_update_options.pressure.type}.

\subsection{Simple pressure correction}
In ref.\cite{Reith:2003} a simple linear attractive potential was added to the coarse-grained potential
\begin{equation}
  \Delta V(r)=A \left( 1-\frac{r}{r_{cutoff}} \right) \,,
\end{equation}
with prefactor $A$
\begin{equation}
  A = -\sign(\Delta P)0.1k_{B}T\min(1,|f\Delta P) \,,
\end{equation}
$\Delta p=P_i-P_\text{target}$, and scaling factor $f$ and $P_\text{target}$ can be specified in the settings file as \interopt{inverse.post_update_options.pressure.simple.scale} and \interopt{inverse.p_target}.

As an example for a block doing simple pressure correction, every third interaction is
\begin{lstlisting}
<post_update>pressure</post_update>
<post_update_options>
  <pressure>
    <type>simple</type>
    <do>0 0 1</do>
    <simple>
      <scale>0.0003</scale>
    </simple>
  </pressure
</post_update_options>
\end{lstlisting}
Here, \interopt{inverse.post_update_options.pressure.simple.scale} is the scaling factor $f$. In order to get the correct pressure it can become necessary to tune the scaling factor $f$ during the iterative process.

\subsection{Advanced pressure correction}
In \cite{Wang:2009} a pressure correction based on the virial expression of the pressure was introduced. The potential term remains as in the simple form while a different sturcture of the $A$ factor is used:
\begin{equation}
  A = \left[\frac{-2\pi\rho^{2}}{3r_{cut}}\int_{0}^{r_{cut}}r^{3}g_{i}(r)dr\right]A_{i}=\Delta P.
\end{equation}
This factor requires the particle density $ \rho $ as additional input parameter, which is added as  \interopt{inverse.particle_dens} in the input file.

\section{Kirkwood-Buff correction}
In order to reproduce the exact Kirkwood-Buff ingetrals (KBIs), an correction term can be added into the coarse-grained potential~\cite{Ganguly:2012},
\begin{equation}
  \Delta U_{ij}^{(n)}(r) = \frac{k_{B}T}\;A\;(G_{ij}^{(n)} - G_{ij}^\text{ref})\left(1- \frac{r}{r_\text{ramp}}\right),
\end{equation}
where $G_{ij}^{(ref)}$ is the KBI calculated from the reference all-atom simulation and $G_{ij}^{(n)}$ is the KBI 
after the $n^{th}$ iteration.

The Kirkwood-Buff integrals are calculated from the radial distribution functions as follows:
\begin{equation}
G_{ij} = 4\pi \int_0^\infty \left[ g_{ij}(r) - 1\right] r^2 dr~.
\label{eq:kbi}
\end{equation}
For simulations of finite box size we calculate the running integral up to distance $R$
\begin{equation}
  G_{ij}(R) = 4\pi \int_0^R \left[ g_{ij}(r) - 1\right] r^2 dr~.
\end{equation}
The average of those running integrals in the interval, where $G_{ij}(R)$ gets flat, gives a good estimate for $G_{ij}$:
\begin{equation}
  G_{ij}\approx<G_{ij}(R)>|_{R=r_1}^{R=r_2}
\end{equation}
As an example for a block doing Kirkwood-Buff correction, every iteraction without doing potential update
\begin{lstlisting}
<do_potential>0</do_potential>
<post_update>kbibi</post_update>
<post_update_options>
  <kbibi>
    <do>1</do>
    <start>1.0</start>
    <stop>1.4</stop>
    <factor>0.05</factor>
    <r_ramp>1.4</r_ramp>
  </kbibi>
</post_update_options>
\end{lstlisting}
Here, \interopt{inverse.post_update_options.kbibi.factor} is the scaling factor $A$. \interopt{inverse.post_update_options.kbibi.start} is $r_1$ and \interopt{inverse.post_update_options.kbibi.stop} is $r_2$ used to calculate the average of $G_{ij}(R)$.
\section{Runtime optimization}
\label{ref:ibi:optimize}
Most time per iteration is spent on running the coarse-grained system and on calculating the statistics. To get a feeling on how much statistics is needed, it is recommended to plot the distribution functions and check whether they are sufficiently smooth. Bad statistics lead to rough potential updates which might cause the iterative refinement to fail. All runs should be long enough to produce distributions/rdfs of reasonable quality.

Often, runtime can be improved by smoothing the potential updates. Our experience has shown that it is better to smooth the potential update instead of the rdf or potential itself. If the potential or rdf is smoothed, sharp features like the first peak in \spce water might get lost. Smoothing on the delta potential works quite well, since the sharp features are already present from the initial guess. By applying iterations of a simple triangular smoothing ($ \Delta U_i = 0.25 \Delta U_{i-1} + 0.5\Delta U_i + 0.25\Delta U_{i+1} $), a reasonable coarse-grained potential for \spce water could be produced in less than 10 minutes. Smoothing is implemented as a post\_update script and can be enabled by adding
\begin{lstlisting}
  <post_update>smooth</post_update>
  <post_update_options>
    <smooth>
        <iterations>2</iterations>
    </smooth>
  </post_update_options>
\end{lstlisting}
to the inverse section of an interaction in the settings \xml file.

\input{usage/cibi}
