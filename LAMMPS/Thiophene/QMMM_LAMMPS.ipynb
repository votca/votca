{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QMMM workflow using LAMMPS and VOTCA-XTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is this tutorial about\n",
    "In this tutorial, we will learn how to set and perform excited state calculation using the Votca XTP library. We will use thiophene as our QM region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "* You will need to install **VOTCA** using the instructions described [here](https://github.com/votca/votca/blob/master/share/doc/INSTALL.rst)\n",
    "* Once the installation is completed you need to activate the VOTCA enviroment by running the `VOTCARC.bash` script that has been installed at the bin subfolder for the path that you have provided for the installation step above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the XTP command line interface\n",
    "The XTP package offers the following command line interface that the user can interact with:\n",
    "* [xtp_map](https://www.votca.org/xtp/xtp_map.html)\n",
    "* [xtp_parallel](https://www.votca.org/xtp/xtp_parallel.html)\n",
    "* [xtp_run](https://www.votca.org/xtp/xtp_run.html)\n",
    "* [xtp_tools](https://www.votca.org/xtp/xtp_tools.html)\n",
    "\n",
    "Run the following command to view the help message of `xtp_tools`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_tools -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "> * In Jupyter the `!` symbol means: *run the following command as a standard unix command*\n",
    "> * In Jupyter the command `%env` set an environmental variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove previous hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f state.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the topology from the Gromacs file\n",
    "We will first generate the mapping from MD coordinates to segments, creating an [hdf5 file](https://www.hdfgroup.org/solutions/hdf5/) to store the results. You can explore the generated `state.hdf5` file with e.g. hdf5itebrowser. In Python, you can use the [h5py library](https://www.h5py.org/). The command to generate the mapping is the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_map -v -t MD_FILES/newfile.data -c MD_FILES/traj.dump -s system.xml -f state.hdf5 -i 99 > mapping.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Check the mapping\n",
    "\n",
    "Let us first output `.pdb` files for the segments, qmmolecules and classical segments in order to check the mapping. So we have to pass the calculator the filename. Votca has two ways to specify options for calculators. Using a file with the `-o` option or for quick things using the `-c` option on the command line, we will use both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [mapchecker section of the manual](https://www.votca.org/xtp/mapchecker.html) you can find a table with the `mapchecker` input variables and their corresponding defaults. Finally, the following command run the check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_run -e mapchecker -c map_file=system.xml -f state.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborlist Calculation\n",
    "The following step is to determine the neighbouring pairs for exciton transport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a cutoff of 1.5 nm. If you want to have a look at an option just the `-d` option with the calculator name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_run -d neighborlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_run -e neighborlist -c constant=1.5 -f state.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read reorganization energies\n",
    "In this step we will read the in site reorganization energies and store them in the `state.hdf5` file. We just need to copy the input file and execute the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_run -e einternal -f state.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute site energy\n",
    "In this step we will perform some *QMMM* calculations to compute the site energies. The `qmmm_mm.xml` file contains more options to perform the *MM* calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_parallel -e qmmm -o qmmm_mm.xml -f state.hdf5 -j \"write\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous command generates a `qmmm_mm_jobs.xml` containing 3000 *MM* jobs to compute, if you examine that file, it should look something like:\n",
    "```xml\n",
    "<jobs>\n",
    "        <job>\n",
    "                <id>0</id>\n",
    "                <tag>thiophene_0:n</tag>\n",
    "                <input>\n",
    "                        <site_energies>0:n</site_energies>\n",
    "                        <regions>\n",
    "                                <region>\n",
    "                                        <id>0</id>\n",
    "                                        <segments>0:n</segments>\n",
    "                                </region>\n",
    "                        </regions>\n",
    "                </input>\n",
    "                <status>AVAILABLE</status>\n",
    "        </job>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run just the first 4 jobs by settings all jobs `status` to `COMPLETE` except for the first four. This can be easily done with [sed](https://www.gnu.org/software/sed/manual/sed.html) as follows,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i \"s/AVAILABLE/COMPLETE/g\" qmmm_mm_jobs.xml\n",
    "!sed -i '0,/COMPLETE/s/COMPLETE/AVAILABLE/' qmmm_mm_jobs.xml\n",
    "!sed -i '0,/COMPLETE/s/COMPLETE/AVAILABLE/' qmmm_mm_jobs.xml\n",
    "!sed -i '0,/COMPLETE/s/COMPLETE/AVAILABLE/' qmmm_mm_jobs.xml\n",
    "!sed -i '0,/COMPLETE/s/COMPLETE/AVAILABLE/' qmmm_mm_jobs.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the jobs and save the results in the state file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_parallel -e qmmm -o qmmm_mm.xml -f state.hdf5 -j \"run\"\n",
    "!xtp_parallel -e qmmm -o qmmm_mm.xml -f state.hdf5 -j \"read\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site energy and pair energy analysis\n",
    "In this step we generate an histogram and compute the correlation function of site energies and pair energy differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_run -e eanalyze -f state.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see a set of files prefixed with `eanalyze` containing the histrogram and correlation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls eanalyze*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QM energy calculation\n",
    "Our next task is to perform the qm calculations for each segment that we have stored in the hdf5 file. The calculations take place in 3 stages: write the jobs to a file, perform the computation and finally save the results to the state file. We created a small option file to make the calculation cheaper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat OPTIONFILES/eqm.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of computational time let just compute the `gw` approximation and the `singlet`. You can also request the `triplet` or `all`,  see the [gwbse sectionfor the eqm calculator](https://www.votca.org/xtp/eqm.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will write the job in a file and enable only the first 2 jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_parallel -e eqm -o eqm.xml -f state.hdf5 -j \"write\"\n",
    "!sed -i \"s/AVAILABLE/COMPLETE/g\" eqm.jobs\n",
    "!sed -i '0,/COMPLETE/s/COMPLETE/AVAILABLE/' eqm.jobs\n",
    "!sed -i '0,/COMPLETE/s/COMPLETE/AVAILABLE/' eqm.jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let run these 2 jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used some more options. `-o` allows us to read in a file with options. `-j` changes the writing to running in this case. `-x` determines how many cores should be used for each job. We can also run multiple jobs in parallel using `-p`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_parallel -e eqm -o eqm.xml -f state.hdf5 -j run -x 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QM calculation for pairs\n",
    "In the following step we will run QM calculations for each pair in the hdf5 file. As the calculations on the previous step, we will first write the jobs in a file, then run them and finally store the results in the state file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous section, we set the GWBSE mode to `G0W0`and the `ranges` to `full`, but we compute only the `gw` approximation. We do not need the BSE results for the coupling calculations. For more information, check the [iqm calculator options](https://www.votca.org/xtp/iqm.html). We also want to compute the `singlet` couplings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the calculations, we need to specify in the `iqm` input which states to read into the jobfile for each segment type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write the jobs to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_parallel -e iqm -o iqm.xml -f state.hdf5 -s 0 -j \"write\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the jobs that we just write down, let's make available only the first job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i \"s/AVAILABLE/COMPLETE/g\" iqm.jobs\n",
    "!sed -i '0,/COMPLETE/s/COMPLETE/AVAILABLE/' iqm.jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run and store the jobs results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_parallel -e iqm -o iqm.xml -f state.hdf5 -s 0 -j run -q 1 -x 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we read the results into the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_parallel -e iqm -o iqm.xml -f state.hdf5 -j \"read\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QMMM Calculations\n",
    "We will run the *QMMM* calculations we will use the pregenerated `qmmm.jobs` file in the current work directory, so we can directly run the calculations. We also provide an option file in the `OPTIONFILES` folder. In qmmm calculations you can use the `jobfile` tag inside the optionfile to modify options from the jobfile. Here we modify the size of the staticregion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat qmmm.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the jobfile we then provide the specific option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat qmmm.jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xtp_parallel -e qmmm -o qmmm.xml -f state.hdf5 -j run -x 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can if we want plot the spectra from both calculations, for which we have to read the energies and oscillator strengths from the checkpoint files. We need the h5py package for python for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def getEnergies(orb):\n",
    "    a=orb['region_0']['orbitals']['BSE_singlet']['eigenvalues'][()]\n",
    "    a.flatten()\n",
    "    return a.flatten()\n",
    "\n",
    "def trans_sort(index):\n",
    "    return int(index[3:])\n",
    "\n",
    "def getOscillators(orb):\n",
    "    energies=getEnergies(orb)\n",
    "    transdip=[]\n",
    "    for k in sorted(orb['region_0']['orbitals']['transition_dipoles'].keys(),key=trans_sort):\n",
    "        transdip.append(np.array(orb['region_0']['orbitals']['transition_dipoles'][k][()]))\n",
    "    d2=[]\n",
    "    for b in transdip:\n",
    "        d2.append(np.sum(b**2))    \n",
    "    d2=np.array(d2)\n",
    "    oscs=2/3.0*energies*d2\n",
    "    return oscs\n",
    "\n",
    "def getSpectrum(filename):\n",
    "    orb=h5py.File(filename,'r')\n",
    "    e=getEnergies(orb)*27.2114\n",
    "    osc=getOscillators(orb)\n",
    "    return e,osc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find the orb files in the `QMMM/frame_10000` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_static=getSpectrum(\"QMMM/frame_10000/job_1_static/checkpoint_iter_1.hdf5\")\n",
    "spectrum_vacuum=getSpectrum(\"QMMM/frame_10000/job_0_vacuum/checkpoint_iter_1.hdf5\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.vlines(spectrum_static[0],0,spectrum_static[1],label=\"static\",color='r')\n",
    "plt.vlines(spectrum_vacuum[0],0,spectrum_vacuum[1],label=\"vacuum\",color='g')\n",
    "plt.xlabel(\"energy [eV]\")\n",
    "plt.ylabel(\"intensity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
